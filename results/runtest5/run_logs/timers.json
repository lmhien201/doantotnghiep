{
    "name": "root",
    "gauges": {
        "shooter.Policy.Entropy.mean": {
            "value": 2.10813307762146,
            "min": 2.10813307762146,
            "max": 2.10813307762146,
            "count": 1
        },
        "shooter.Policy.Entropy.sum": {
            "value": 106216.1796875,
            "min": 106216.1796875,
            "max": 106216.1796875,
            "count": 1
        },
        "shooter.Step.mean": {
            "value": 49939.0,
            "min": 49939.0,
            "max": 49939.0,
            "count": 1
        },
        "shooter.Step.sum": {
            "value": 49939.0,
            "min": 49939.0,
            "max": 49939.0,
            "count": 1
        },
        "shooter.Policy.ExtrinsicValueEstimate.mean": {
            "value": -3.8104259967803955,
            "min": -3.8104259967803955,
            "max": -3.8104259967803955,
            "count": 1
        },
        "shooter.Policy.ExtrinsicValueEstimate.sum": {
            "value": -3322.69140625,
            "min": -3322.69140625,
            "max": -3322.69140625,
            "count": 1
        },
        "shooter.Environment.EpisodeLength.mean": {
            "value": 266.9050279329609,
            "min": 266.9050279329609,
            "max": 266.9050279329609,
            "count": 1
        },
        "shooter.Environment.EpisodeLength.sum": {
            "value": 47776.0,
            "min": 47776.0,
            "max": 47776.0,
            "count": 1
        },
        "shooter.Environment.CumulativeReward.mean": {
            "value": -1293.217877094972,
            "min": -1293.217877094972,
            "max": -1293.217877094972,
            "count": 1
        },
        "shooter.Environment.CumulativeReward.sum": {
            "value": -231486.0,
            "min": -231486.0,
            "max": -231486.0,
            "count": 1
        },
        "shooter.Policy.ExtrinsicReward.mean": {
            "value": -1293.217877094972,
            "min": -1293.217877094972,
            "max": -1293.217877094972,
            "count": 1
        },
        "shooter.Policy.ExtrinsicReward.sum": {
            "value": -231486.0,
            "min": -231486.0,
            "max": -231486.0,
            "count": 1
        },
        "shooter.Losses.PolicyLoss.mean": {
            "value": 0.015697098224579046,
            "min": 0.015697098224579046,
            "max": 0.015697098224579046,
            "count": 1
        },
        "shooter.Losses.PolicyLoss.sum": {
            "value": 0.03139419644915809,
            "min": 0.03139419644915809,
            "max": 0.03139419644915809,
            "count": 1
        },
        "shooter.Losses.ValueLoss.mean": {
            "value": 750.1386393229167,
            "min": 750.1386393229167,
            "max": 750.1386393229167,
            "count": 1
        },
        "shooter.Losses.ValueLoss.sum": {
            "value": 1500.2772786458333,
            "min": 1500.2772786458333,
            "max": 1500.2772786458333,
            "count": 1
        },
        "shooter.Policy.LearningRate.mean": {
            "value": 0.00014953872030752001,
            "min": 0.00014953872030752001,
            "max": 0.00014953872030752001,
            "count": 1
        },
        "shooter.Policy.LearningRate.sum": {
            "value": 0.00029907744061504003,
            "min": 0.00029907744061504003,
            "max": 0.00029907744061504003,
            "count": 1
        },
        "shooter.Policy.Epsilon.mean": {
            "value": 0.19969248,
            "min": 0.19969248,
            "max": 0.19969248,
            "count": 1
        },
        "shooter.Policy.Epsilon.sum": {
            "value": 0.39938496,
            "min": 0.39938496,
            "max": 0.39938496,
            "count": 1
        },
        "shooter.Policy.Beta.mean": {
            "value": 0.004984654751999999,
            "min": 0.004984654751999999,
            "max": 0.004984654751999999,
            "count": 1
        },
        "shooter.Policy.Beta.sum": {
            "value": 0.009969309503999999,
            "min": 0.009969309503999999,
            "max": 0.009969309503999999,
            "count": 1
        },
        "shooter.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 1
        },
        "shooter.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 1
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1726655779",
        "python_version": "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\hienl\\mlagent 2\\venv\\Scripts\\mlagents-learn Assets/hunter.yaml --time-scale=5 --run-id=runtest5",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.4.1+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1726658261"
    },
    "total": 2482.5740229000003,
    "count": 1,
    "self": 0.013934900001913775,
    "children": {
        "run_training.setup": {
            "total": 0.09442900000067311,
            "count": 1,
            "self": 0.09442900000067311
        },
        "TrainerController.start_learning": {
            "total": 2482.4656589999977,
            "count": 1,
            "self": 0.1601965999470849,
            "children": {
                "TrainerController._reset_env": {
                    "total": 7.570104499998706,
                    "count": 1,
                    "self": 7.570104499998706
                },
                "TrainerController.advance": {
                    "total": 2474.52840330005,
                    "count": 4976,
                    "self": 0.14239089993134257,
                    "children": {
                        "env_step": {
                            "total": 2442.701510500061,
                            "count": 4976,
                            "self": 2430.6516883998192,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 11.951938600159338,
                                    "count": 4976,
                                    "self": 0.4584932003017457,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 11.493445399857592,
                                            "count": 4752,
                                            "self": 11.493445399857592
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.09788350008238922,
                                    "count": 4975,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 2408.4750219000853,
                                            "count": 4975,
                                            "is_parallel": true,
                                            "self": 55.569915400235914,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0010655999976734165,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00029779999749735,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0007678000001760665,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0007678000001760665
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 2352.9040408998517,
                                                    "count": 4975,
                                                    "is_parallel": true,
                                                    "self": 1.6427952997473767,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 2.3874240999393805,
                                                            "count": 4975,
                                                            "is_parallel": true,
                                                            "self": 2.3874240999393805
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 2344.230181000021,
                                                            "count": 4975,
                                                            "is_parallel": true,
                                                            "self": 2344.230181000021
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 4.643640500144102,
                                                            "count": 4975,
                                                            "is_parallel": true,
                                                            "self": 1.334978000002593,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 3.3086625001415086,
                                                                    "count": 19900,
                                                                    "is_parallel": true,
                                                                    "self": 3.3086625001415086
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 31.684501900057512,
                            "count": 4975,
                            "self": 0.24915280005006935,
                            "children": {
                                "process_trajectory": {
                                    "total": 8.310764700010623,
                                    "count": 4975,
                                    "self": 8.310764700010623
                                },
                                "_update_policy": {
                                    "total": 23.12458439999682,
                                    "count": 3,
                                    "self": 13.700084799984324,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 9.424499600012496,
                                            "count": 90,
                                            "self": 9.424499600012496
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.20695460000206367,
                    "count": 1,
                    "self": 0.014743800002179341,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.19221079999988433,
                            "count": 1,
                            "self": 0.19221079999988433
                        }
                    }
                }
            }
        }
    }
}